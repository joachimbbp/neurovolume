{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "More or less a clone of `bold_register_scratch.ipynb` only now we are going to rely on manually alignment instead of the always failing ML models from ANTs. I don't mean to entirely imply that it is ANTs' fault, I might be misusing the models. However, it's proving difficult, and iterating over something that takes so long to align is taking forever. So lets go with the manual alignment.\n",
    "\n",
    "**steps**\n",
    "We will load all the data, run motion correction, and then manually align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_viewer_functions import *\n",
    "from functions import *\n",
    "from scivol import *\n",
    "import numpy as np\n",
    "import json\n",
    "import ants\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, Button, Output\n",
    "import pickle\n",
    "import napari\n",
    "import matplotlib.transforms as mtransforms\n",
    "import os\n",
    "\n",
    "proj_root = parent_directory()\n",
    "t1_input_filepath = os.path.join(proj_root, \"media/sub-01/anat/sub-01_T1w.nii.gz\")\n",
    "bold_stim_filepath = os.path.join(proj_root, \"media/sub-01/func/sub-01_task-emotionalfaces_run-1_bold.nii.gz\")\n",
    "bold_rest_filepath = os.path.join(proj_root, \"media/sub-01/func/sub-01_task-rest_bold.nii.gz\")\n",
    "mni_anat_filepath =  os.path.join(proj_root, \"templates/mni_icbm152_t1_tal_nlin_sym_09a.nii\")\n",
    "mni_mask_filepath = os.path.join(proj_root, \"templates/mni_icbm152_t1_tal_nlin_sym_09a_mask.nii\")\n",
    "events_tsv_path = os.path.join(proj_root, \"media/sub-01/func/task-emotionalfaces_run-1_events.tsv\")\n",
    "stimulus_image_path = \"/Users/joachimpfefferkorn/repos/emotional-faces-psychopy-task-main/emofaces/POFA/fMRI_POFA\"\n",
    "log_path = \"/Users/joachimpfefferkorn/repos/emotional-faces-psychopy-task-main/emofaces/data/01-subject_emofaces1_2019_Aug_14_1903.log\"\n",
    "cache_folder = \"/Volumes/GlyphA_R1/nvol_cache\"\n",
    "template_folder =  os.path.join(proj_root, \"templates/\")\n",
    "output_folder = os.path.join(proj_root, \"output/\")\n",
    "\n",
    "raw_t1_img = ants.image_read(t1_input_filepath)\n",
    "raw_stim_bold = ants.image_read(bold_stim_filepath)\n",
    "raw_rest_bold_img = ants.image_read(bold_rest_filepath)\n",
    "mni_template = ants.image_read(mni_anat_filepath)\n",
    "mni_mask = ants.image_read(mni_mask_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_image = ants.image_read(bold_stim_filepath)\n",
    "t1_image = ants.image_read(t1_input_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_BOLD(bold_frame: np.ndarray, translation: tuple, scale: tuple, rotation: tuple,):\n",
    "    tx, ty, tz = translation\n",
    "    sx, sy, sz = scale\n",
    "    rx, ry, rz = rotation\n",
    "    translation = np.array([\n",
    "        [1, 0, 0, tx],\n",
    "        [0, 1, 0, ty],\n",
    "        [0, 0, 1, tz],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "# Translation matrices copypasta from GPT\n",
    "    scale = np.array([\n",
    "            [sx, 0,  0,  0],\n",
    "            [0,  sy, 0,  0],\n",
    "            [0,  0,  sz, 0],\n",
    "            [0,  0,  0,  1]\n",
    "        ])\n",
    "\n",
    "# I wonder where the origin is here...\n",
    "    rotation_x = np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, np.cos(rx), -np.sin(rx), 0],\n",
    "        [0, np.sin(rx), np.cos(rx), 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    rotation_y = np.array([\n",
    "        [np.cos(ry), 0, np.sin(ry), 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [-np.sin(ry), 0, np.cos(ry), 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    rotation_z = np.array([\n",
    "        [np.cos(rz), -np.sin(rz), 0, 0],\n",
    "        [np.sin(rz), np.cos(rz), 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    rotation_matrix = rotation_x @ rotation_y @ rotation_z\n",
    "    transformation_matrix = translation @ rotation @ scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_bold_alignment(bold_seq_vol: np.ndarray, anat_vol: np.ndarray, dim='x'):\n",
    "    def x_coord(slice, frame, opacity):\n",
    "        fig, axes = plt.subplots(1,3, figsize=(15,5))\n",
    "\n",
    "        fig.suptitle('x axis view')\n",
    "\n",
    "        axes[0].imshow(bold_seq_vol[slice,:,:, frame], cmap='hot')\n",
    "        axes[0].set_title('BOLD')\n",
    "\n",
    "        axes[1].imshow(anat_vol[slice,:,:], cmap='gray')\n",
    "        axes[1].set_title('Anatomy')\n",
    "\n",
    "        axes[2].imshow(anat_vol[slice,:,:], cmap='gray')\n",
    "        axes[2].imshow(bold_seq_vol[slice,:,:, frame], cmap='hot', alpha=opacity)\n",
    "        axes[2].set_title('Overlay')\n",
    "\n",
    "    def y_coord(slice, frame, opacity):\n",
    "        fig, axes = plt.subplots(1,3, figsize=(15,5))\n",
    "\n",
    "        fig.suptitle('y axis view')\n",
    "\n",
    "        axes[0].imshow(bold_seq_vol[:,slice,:, frame], cmap='hot')\n",
    "        axes[0].set_title('BOLD')\n",
    "\n",
    "        axes[1].imshow(anat_vol[:,slice,:], cmap='gray')\n",
    "        axes[1].set_title('Anatomy')\n",
    "\n",
    "        axes[2].imshow(anat_vol[:,slice,:], cmap='gray')\n",
    "        axes[2].imshow(bold_seq_vol[:,slice,:, frame], cmap='hot', alpha=opacity)\n",
    "        axes[2].set_title('Overlay')\n",
    "\n",
    "    def z_coord(slice, frame, opacity):\n",
    "        fig, axes = plt.subplots(1,3, figsize=(15,5))\n",
    "\n",
    "        fig.suptitle('z axis view')\n",
    "\n",
    "        axes[0].imshow(bold_seq_vol[:,:,slice, frame], cmap='hot')\n",
    "        axes[0].set_title('BOLD')\n",
    "\n",
    "        axes[1].imshow(anat_vol[:,:,slice], cmap='gray')\n",
    "        axes[1].set_title('Anatomy')\n",
    "\n",
    "        axes[2].imshow(anat_vol[:,:,slice], cmap='gray')\n",
    "        axes[2].imshow(bold_seq_vol[:,:,slice, frame], cmap='hot', alpha=opacity)\n",
    "        axes[2].set_title('Overlay')\n",
    "\n",
    "    match dim:\n",
    "        case \"x\":\n",
    "            interact(x_coord, slice=(0, anat_vol.shape[0]-1), frame=(0, bold_seq_vol.shape[3]-1),opacity=(0, 1.0))\n",
    "        case 'y':\n",
    "            interact(y_coord, slice=(0, anat_vol.shape[1]-1), frame=(0, bold_seq_vol.shape[3]-1),opacity=(0, 1.0))\n",
    "        case 'z':\n",
    "            interact(z_coord, slice=(0, anat_vol.shape[2]-1), frame=(0, bold_seq_vol.shape[3]-1),opacity=(0, 1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_brain_mask(anat, mni_template, mni_mask):\n",
    "    #Don't love the term \"anat\" as this should work with BOLD, but what is it if not anatomy?\n",
    "    template_warp_to_raw_anat = ants.registration(\n",
    "    fixed=anat,\n",
    "    moving=mni_template, \n",
    "    type_of_transform='SyN',\n",
    "    verbose=False\n",
    "    )\n",
    "    print(\"Creating brain mask\")\n",
    "    brain_mask = ants.apply_transforms(\n",
    "        fixed=template_warp_to_raw_anat['warpedmovout'],\n",
    "        moving=mni_mask,\n",
    "        transformlist=template_warp_to_raw_anat['fwdtransforms'],\n",
    "        interpolator='nearestNeighbor',\n",
    "        verbose=False\n",
    "    )\n",
    "    return brain_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skull_strip_anat(anat, mni_template, mni_mask, dilate=True):\n",
    "    \"\"\"\n",
    "    anat, mni_template, mni_mask must all be ANTS images.\n",
    "    \"\"\"\n",
    "    print(\"Skull Stripping Anatomy Volume\")\n",
    "    print(\"Registering template to frame\")\n",
    "    brain_mask = generate_brain_mask(anat, mni_template, mni_mask)\n",
    "    if dilate:\n",
    "        print(\"Dilating brain mask\")\n",
    "        brain_mask = ants.morphology(brain_mask, radius=4, operation='dilate', mtype='binary')\n",
    "    print(\"Masking brain\")\n",
    "    isolated_brain = ants.mask_image(anat, brain_mask)\n",
    "    print(\"Done\")\n",
    "    return isolated_brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skull_strip_bold(bold, mni_template, mni_mask, dilate=False):\n",
    "    \"\"\"\n",
    "    Assuming a motion corrected or relatively BOLD image\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Skull strip for BOLD\")\n",
    "    isolated_brain_vol_frames = []\n",
    "    for frame in range(bold.shape[3]):\n",
    "        print(f\"Skull stripping bold frame {frame + 1}/{bold.shape[3]}\")\n",
    "        bold_frame = ants.from_numpy(bold.numpy()[:,:,:,frame],\n",
    "                                    spacing=bold.spacing[:3])\n",
    "        brain_mask = generate_brain_mask(bold_frame, mni_template, mni_mask)\n",
    "        if dilate:\n",
    "            print(\"Dilating brain mask\")\n",
    "            brain_mask = ants.morphology(brain_mask, radius=4, operation='dilate', mtype='binary')\n",
    "        isolated_brain_vol = ants.mask_image(bold_frame, brain_mask).numpy()\n",
    "        isolated_brain_vol_frames.append(isolated_brain_vol)\n",
    "    print(\"Creating new ANTsImage from isolated brain volumes\")\n",
    "    data = np.stack([frame for frame in isolated_brain_vol_frames], axis=3)\n",
    "    isolated_brain_bold_img = ants.from_numpy(data, origin=bold.origin, spacing=bold.spacing)\n",
    "    print(\"Done\")\n",
    "    return isolated_brain_bold_img\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_stabilized_bold_to_anat(bold_img, t1_img, template_frame_idx=0):\n",
    "    \"\"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Aligning stabilized bold to anat\\nEstablishing temporal mean\")\n",
    "    template_frame_idx = ants.from_numpy(bold_img.numpy()[:,:,:,template_frame_idx], spacing=bold_img.spacing[:3])\n",
    "\n",
    "    frame_registration = ants.registration(\n",
    "        fixed=t1_img,\n",
    "        moving=template_frame_idx,\n",
    "        type_of_transform=\"Rigid\", \n",
    "    )\n",
    "    registered_frames = []\n",
    "\n",
    "    print(\"Applying transformations to frames\")\n",
    "    for frame in range(bold_img.shape[3]):\n",
    "        print(f\"frame{frame}/{bold_img.shape[3]}\")\n",
    "        print(\"creating image of bold frame\")\n",
    "        bold_frame = ants.from_numpy(bold_img.numpy()[:,:,:,frame],\n",
    "                                     spacing=bold_img.spacing[:3])\n",
    "        print(\"     Applying frame transformation\")\n",
    "        registered_frame = ants.apply_transforms(\n",
    "            fixed=t1_img,\n",
    "            moving=bold_frame,\n",
    "            transformlist=frame_registration['fwdtransforms'],\n",
    "            interpolator='linear'\n",
    "        )\n",
    "        print(\"     adding registered frame to list\")\n",
    "        registered_frames.append(registered_frame.numpy())\n",
    "    print(\"Creating 4D numpy vol from list of 3D ANTs imgs\")\n",
    "    data = np.stack([frame for frame in registered_frames], axis=3)\n",
    "    print(\"Creating 4D bold image from numpy vol\")\n",
    "    registered_bold_img = ants.from_numpy(data, origin=bold_img.origin, spacing=bold_img.spacing)\n",
    "    return registered_bold_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skull Stripping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skull Stripping Anatomy Volume\n",
      "Registering template to frame\n",
      "Creating brain mask\n",
      "Dilating brain mask\n",
      "Masking brain\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "isolated_t1 = skull_strip_anat(t1_image, mni_template, mni_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skull strip for BOLD\n",
      "Skull stripping bold frame 1/10\n",
      "Creating brain mask\n",
      "Skull stripping bold frame 2/10\n",
      "Creating brain mask\n",
      "Skull stripping bold frame 3/10\n",
      "Creating brain mask\n",
      "Skull stripping bold frame 4/10\n",
      "Creating brain mask\n",
      "Skull stripping bold frame 5/10\n",
      "Creating brain mask\n",
      "Skull stripping bold frame 6/10\n",
      "Creating brain mask\n",
      "Skull stripping bold frame 7/10\n",
      "Creating brain mask\n",
      "Skull stripping bold frame 8/10\n",
      "Creating brain mask\n",
      "Skull stripping bold frame 9/10\n",
      "Creating brain mask\n",
      "Skull stripping bold frame 10/10\n",
      "Creating brain mask\n",
      "Creating new ANTsImage from isolated brain volumes\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Truncated Version\n",
    "sliced = bold_image.numpy()[:, :, :, :10]\n",
    "bold_truncated_img = ants.from_numpy(sliced, spacing=bold_image.spacing, origin=bold_image.origin, direction=bold_image.direction)\n",
    "#stabilized = ants.motion_correction(bold_image)\n",
    "stabilized_truncated = ants.motion_correction(bold_truncated_img)\n",
    "isolated_bold = skull_strip_bold(stabilized_truncated['motion_corrected'], mni_template, mni_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check in napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'T1 full anat' at 0x30c691490>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(np.transpose(isolated_bold.numpy(), axes=(3,0,1,2)), name=\"BOLD\")\n",
    "# viewer.add_image(t1_image.numpy(), name=\"T1 full anat\")\n",
    "# viewer.add_image(isolated_t1.numpy(), name=\"T1 Brain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Meat of it All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alignment hasn't been working without skull stripping, so let's reintroduce that\n",
    "\n",
    "\n",
    "Of note, `AntsPyNet` has a built in function that might be a bit more robust. However, it is heavy and falls into dependency hell quite quickly. It would be worth playing around with, but the heaviness of the package might be antithetical to Neurovolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_BOLD = align_stabilized_bold_to_anat(stabilized_truncated['motion_corrected'], t1_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewer.add_image(isolated_t1.numpy(), name=\"t1\")\n",
    "# viewer.add_image(np.transpose(registered_BOLD.numpy(), axes=(3,0,1,2)), name=\"Bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(registered_BOLD)\n",
    "print(t1_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_bold_alignment_legacy(registered_BOLD.numpy(), t1_image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
