{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project root: /Users/joachimpfefferkorn/repos/neurovolume\n"
     ]
    }
   ],
   "source": [
    "from notebook_viewer_functions import *\n",
    "from functions import *\n",
    "from scivol import *\n",
    "import numpy as np\n",
    "import json\n",
    "import ants\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "proj_root = parent_directory()\n",
    "print(f\"project root: {proj_root}\")\n",
    "t1_input_filepath = os.path.join(proj_root, \"media/sub-01/anat/sub-01_T1w.nii.gz\")\n",
    "bold_stim_filepath = os.path.join(proj_root, \"media/sub-01/func/sub-01_task-emotionalfaces_run-1_bold.nii.gz\")\n",
    "bold_rest_filepath = os.path.join(proj_root, \"media/sub-01/func/sub-01_task-rest_bold.nii.gz\")\n",
    "mni_anat_filepath =  os.path.join(proj_root, \"templates/mni_icbm152_t1_tal_nlin_sym_09a.nii\")\n",
    "mni_mask_filepath = os.path.join(proj_root, \"templates/mni_icbm152_t1_tal_nlin_sym_09a_mask.nii\")\n",
    "events_tsv_path = os.path.join(proj_root, \"media/sub-01/func/task-emotionalfaces_run-1_events.tsv\")\n",
    "stimulus_image_path = \"/Users/joachimpfefferkorn/repos/emotional-faces-psychopy-task-main/emofaces/POFA/fMRI_POFA\"\n",
    "log_path = \"/Users/joachimpfefferkorn/repos/emotional-faces-psychopy-task-main/emofaces/data/01-subject_emofaces1_2019_Aug_14_1903.log\"\n",
    "\n",
    "raw_t1_img = ants.image_read(t1_input_filepath)\n",
    "raw_stim_bold = ants.image_read(bold_stim_filepath)\n",
    "raw_rest_bold_img = ants.image_read(bold_rest_filepath)\n",
    "mni_img = ants.image_read(mni_anat_filepath)\n",
    "mni_mask_img = ants.image_read(mni_mask_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat adapted from a GPT response, let's first make sure that our registration applies to one frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_image = ants.image_read(bold_stim_filepath)  # Replace with your BOLD image path\n",
    "t1_image = ants.image_read(t1_input_filepath)     # Replace with your T1 image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6923299ca5d43efbe251a417ee2b3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=255, description='slice', max=511), Output()), _dom_classes=('widget-intâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_slice = ants.from_numpy(bold_image.numpy()[:,:,:,0], spacing=bold_image.spacing[:3])\n",
    "slice_registration = ants.registration(\n",
    "    fixed=t1_image,\n",
    "    moving=test_slice,\n",
    "    type_of_transform='Rigid'  # You can also use 'Affine' or 'SyN' for deformable registration\n",
    ")\n",
    "\n",
    "bold_slice_registered = ants.apply_transforms(\n",
    "    fixed=t1_image,\n",
    "    moving=test_slice,\n",
    "    transformlist=slice_registration['fwdtransforms'],\n",
    "    interpolator='linear'\n",
    ")\n",
    "explore_3D_vol(bold_slice_registered.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bold_slice_registered)\n",
    "print(t1_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The following does not (it crashes the kernel):\n",
    "\n",
    "````\n",
    "bold_registered = ants.apply_transforms(\n",
    "    fixed=t1_image,\n",
    "    moving=bold_image,\n",
    "    transformlist=registration['fwdtransforms'],\n",
    "    interpolator='linear',\n",
    "    imagetype=3\n",
    ")\n",
    "````\n",
    "\n",
    "I suspect this has to do with a glitch on the image type 3 as this was also an issue yesterday. Perhaps open an issue on github\n",
    "\n",
    "As a workaround, let's use a loop to cycle through all the 4th dimensional stuff.\n",
    "\n",
    "Given the computational lift of registration, let's write them to a list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, perhaps you could have made this a dictionary `img:transforms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registrations = []\n",
    "for frame in range(bold_image.shape[3]):\n",
    "    print(f\"frame {frame}/{bold_image.shape[3]}\")\n",
    "    print(\" creating bold frame\")\n",
    "    bold_frame = ants.from_numpy(bold_image.numpy()[:,:,:,frame])\n",
    "\n",
    "    print(\" Registering bold frame to T1 image\")\n",
    "    registration = ants.registration(\n",
    "    fixed=t1_image,\n",
    "    moving=bold_frame,\n",
    "    type_of_transform='Rigid'  # You can also use 'Affine' or 'SyN' for deformable registration\n",
    "    )\n",
    "    registrations += registration #This is incorrect! It's just adding the var names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My cat turned off my laptop and I lost the first 43 minute run of the transforms creation. Let's save this to a cache real quick so that doesn't happen again. (if that will even work, it looks like it's just a list of variables, that might get flushed by Python? Dig into this more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/joachimpfefferkorn/repos/neurovolume/cache/transforms.txt\", \"w\") as transforms_file:\n",
    "    transforms_file.write(str(registrations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create an empty 4D volume to put all these frames in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_np = np.empty((t1_image.shape[0], t1_image.shape[1], t1_image.shape[2], bold_image.shape[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we populate it, a quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 296, 185)\n",
      "(64, 64, 35, 185)\n",
      "185\n",
      "/var/folders/m4/rtcmkx_17lv03n9tvdf76ycr0000gn/T/tmp8mxi9mr_0GenericAffine.mat\n"
     ]
    }
   ],
   "source": [
    "print(result_np.shape)\n",
    "print(bold_image.shape)\n",
    "print(len(registrations))\n",
    "print(registrations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.0, 4.0, 4.0, 2.0)\n"
     ]
    }
   ],
   "source": [
    "print(bold_image.spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_slice = ants.from_numpy(bold_image.numpy()[:,:,:,0], spacing=bold_image.spacing[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
