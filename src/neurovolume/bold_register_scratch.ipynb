{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project root: /Users/joachimpfefferkorn/repos/neurovolume\n"
     ]
    }
   ],
   "source": [
    "from notebook_viewer_functions import *\n",
    "from functions import *\n",
    "from scivol import *\n",
    "import numpy as np\n",
    "import json\n",
    "import ants\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "proj_root = parent_directory()\n",
    "print(f\"project root: {proj_root}\")\n",
    "t1_input_filepath = os.path.join(proj_root, \"media/sub-01/anat/sub-01_T1w.nii.gz\")\n",
    "bold_stim_filepath = os.path.join(proj_root, \"media/sub-01/func/sub-01_task-emotionalfaces_run-1_bold.nii.gz\")\n",
    "bold_rest_filepath = os.path.join(proj_root, \"media/sub-01/func/sub-01_task-rest_bold.nii.gz\")\n",
    "mni_anat_filepath =  os.path.join(proj_root, \"templates/mni_icbm152_t1_tal_nlin_sym_09a.nii\")\n",
    "mni_mask_filepath = os.path.join(proj_root, \"templates/mni_icbm152_t1_tal_nlin_sym_09a_mask.nii\")\n",
    "events_tsv_path = os.path.join(proj_root, \"media/sub-01/func/task-emotionalfaces_run-1_events.tsv\")\n",
    "stimulus_image_path = \"/Users/joachimpfefferkorn/repos/emotional-faces-psychopy-task-main/emofaces/POFA/fMRI_POFA\"\n",
    "log_path = \"/Users/joachimpfefferkorn/repos/emotional-faces-psychopy-task-main/emofaces/data/01-subject_emofaces1_2019_Aug_14_1903.log\"\n",
    "\n",
    "raw_t1_img = ants.image_read(t1_input_filepath)\n",
    "raw_stim_bold = ants.image_read(bold_stim_filepath)\n",
    "raw_rest_bold_img = ants.image_read(bold_rest_filepath)\n",
    "mni_img = ants.image_read(mni_anat_filepath)\n",
    "mni_mask_img = ants.image_read(mni_mask_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_image = ants.image_read(bold_stim_filepath)  # Replace with your BOLD image path\n",
    "t1_image = ants.image_read(t1_input_filepath)     # Replace with your T1 image path\n",
    "\n",
    "\n",
    "# If the BOLD image is 4D, extract the mean image for registration\n",
    "if bold_image.dimension == 4:\n",
    "    bold_mean_np = bold_image.numpy().mean(axis=-1)  # Compute the mean along the time axis\n",
    "    bold_mean = ants.from_numpy(bold_mean_np, spacing=bold_image.spacing[:3])\n",
    "else:\n",
    "    bold_mean = bold_image\n",
    "\n",
    "# Perform registration\n",
    "registration = ants.registration(\n",
    "    fixed=t1_image,\n",
    "    moving=bold_mean,\n",
    "    type_of_transform='Rigid'  # You can also use 'Affine' or 'SyN' for deformable registration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOLD image dimensions: 4, shape: (64, 64, 35, 185)\n",
      "T1 image dimensions: 3, shape: (512, 512, 296)\n",
      "Forward Transforms: ['/var/folders/m4/rtcmkx_17lv03n9tvdf76ycr0000gn/T/tmpq30xmcav0GenericAffine.mat']\n"
     ]
    }
   ],
   "source": [
    "print(f\"BOLD image dimensions: {bold_image.dimension}, shape: {bold_image.shape}\")\n",
    "print(f\"T1 image dimensions: {t1_image.dimension}, shape: {t1_image.shape}\")\n",
    "print(f\"Forward Transforms: {registration['fwdtransforms']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_mean_registered = ants.apply_transforms(\n",
    "    fixed=t1_image,\n",
    "    moving=bold_mean,\n",
    "    transformlist=registration['fwdtransforms'],\n",
    "    interpolator='linear'\n",
    ")\n",
    "ants.image_write(bold_mean_registered, 'bold_mean_registered.nii.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTsImage (LPI)\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (512, 512, 296)\n",
      "\t Spacing    : (0.4785, 0.4785, 0.5)\n",
      "\t Origin     : (119.989, 104.52, -84.2457)\n",
      "\t Direction  : [-1.      0.0025  0.     -0.0025 -1.      0.      0.      0.      1.    ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe36a6ad15b8446f92e71c0710fe814e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=255, description='slice', max=511), Output()), _dom_classes=('widget-intâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(bold_mean_registered)\n",
    "explore_3D_vol(bold_mean_registered.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS WORKS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformation to the full BOLD sequence\n",
    "bold_registered = ants.apply_transforms(\n",
    "    fixed=t1_image,\n",
    "    moving=bold_image,\n",
    "    transformlist=registration['fwdtransforms'],\n",
    "    interpolator='linear',\n",
    "    imagetype=3  # Specify imagetype=3 for 4D images\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the registered BOLD image\n",
    "ants.image_write(bold_registered, 'bold_registered_to_t1.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have a hunch this is correct but let's see:\n",
    "spacing = (1/raw_t1_img.spacing[0], 1/raw_t1_img.spacing[1], 1/raw_t1_img.spacing[2])\n",
    "print(spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_frame_img = ants.from_numpy(raw_stim_bold.numpy()[:,:,:,1])\n",
    "#bold_resampled = ants.resample_image(bold_frame_img, spacing, use_voxels=False)\n",
    "bold_resampled = ants.resample_image(bold_frame_img, spacing, use_voxels=False)\n",
    "\n",
    "registered_frame = ants.registration(\n",
    "    fixed=mni_img,\n",
    "    moving=bold_resampled,\n",
    "    type_of_transform='SyNBold',\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(registered_frame['fwdtransforms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempted_bold = ants.apply_transforms(mni_img, bold_resampled, registered_frame['fwdtransforms'], imagetype=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_3D_vol(attempted_bold.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
