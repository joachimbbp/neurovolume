{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project root: /Users/joachimpfefferkorn/repos/neurovolume\n"
     ]
    }
   ],
   "source": [
    "from notebook_viewer_functions import *\n",
    "from functions import *\n",
    "from scivol import *\n",
    "import numpy as np\n",
    "import json\n",
    "import ants\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "proj_root = parent_directory()\n",
    "print(f\"project root: {proj_root}\")\n",
    "t1_input_filepath = os.path.join(proj_root, \"media/sub-01/anat/sub-01_T1w.nii.gz\")\n",
    "bold_stim_filepath = os.path.join(proj_root, \"media/sub-01/func/sub-01_task-emotionalfaces_run-1_bold.nii.gz\")\n",
    "bold_rest_filepath = os.path.join(proj_root, \"media/sub-01/func/sub-01_task-rest_bold.nii.gz\")\n",
    "mni_anat_filepath =  os.path.join(proj_root, \"templates/mni_icbm152_t1_tal_nlin_sym_09a.nii\")\n",
    "mni_mask_filepath = os.path.join(proj_root, \"templates/mni_icbm152_t1_tal_nlin_sym_09a_mask.nii\")\n",
    "events_tsv_path = os.path.join(proj_root, \"media/sub-01/func/task-emotionalfaces_run-1_events.tsv\")\n",
    "stimulus_image_path = \"/Users/joachimpfefferkorn/repos/emotional-faces-psychopy-task-main/emofaces/POFA/fMRI_POFA\"\n",
    "log_path = \"/Users/joachimpfefferkorn/repos/emotional-faces-psychopy-task-main/emofaces/data/01-subject_emofaces1_2019_Aug_14_1903.log\"\n",
    "\n",
    "raw_t1_img = ants.image_read(t1_input_filepath)\n",
    "raw_stim_bold = ants.image_read(bold_stim_filepath)\n",
    "raw_rest_bold_img = ants.image_read(bold_rest_filepath)\n",
    "mni_img = ants.image_read(mni_anat_filepath)\n",
    "mni_mask_img = ants.image_read(mni_mask_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_bold_alignment(bold_seq_vol: np.ndarray, anat_vol: np.ndarray):\n",
    "    #Just doing the Z dimension for now\n",
    "    #No time, just a BOLD frame\n",
    "    def x_coord(slice_idx, frame_idx, opacity):\n",
    "        fig, axes = plt.subplots(1,3, figsize=(15,5))\n",
    "\n",
    "        axes[0].imshow(bold_seq_vol[:,:,slice_idx, frame_idx], cmap='hot')\n",
    "        axes[0].set_title('BOLD')\n",
    "\n",
    "        axes[1].imshow(anat_vol[:,:,slice_idx], cmap='gray')\n",
    "        axes[1].set_title('Anatomy')\n",
    "\n",
    "        axes[2].imshow(anat_vol[:,:,slice_idx], cmap='gray')\n",
    "        axes[2].imshow(bold_seq_vol[:,:,slice_idx, frame_idx], cmap='hot', alpha=opacity)\n",
    "        axes[2].set_title('Overlay')\n",
    "    interact(x_coord, slice_idx=(0, anat_vol.shape[2]-1), frame_idx=(0, bold_seq_vol.shape[3]-1),opacity=(0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_fMRI(ants_img: ants.core.ants_image.ANTsImage,\n",
    "                volume_override = \"NULL\",\n",
    "                 dim=\"x\", events_tsv=\"NULL\",\n",
    "                 cmap='nipy_spectral'):\n",
    "    if type(volume_override) == np.ndarray:\n",
    "        vol = volume_override\n",
    "    else:\n",
    "        vol = ants_img.numpy()\n",
    "    \n",
    "    def dim_to_indexed(dim, slice, frame):\n",
    "        match dim:\n",
    "            case \"x\":\n",
    "                return vol[slice,:,:,frame]\n",
    "            case \"y\":\n",
    "                return vol[:,slice,:,frame]\n",
    "            case \"z\":\n",
    "                return vol[:,:,slice,frame]\n",
    "\n",
    "    def plot(slice, frame):\n",
    "        second = float(frame * ants_img.spacing[3])\n",
    "        plt.figure()\n",
    "        plt.imshow(dim_to_indexed(dim, slice, frame), cmap=cmap)\n",
    "        plt.show()\n",
    "        present_event = \"No event file\"\n",
    "        if events_tsv != \"NULL\":\n",
    "            for event in events_tsv.split(\"\\n\"):\n",
    "                info = event.split(\"\t\")\n",
    "                if info[0].isdigit() and info[1].isdigit():\n",
    "                    if float(info[0]) <= second < float(info[0] + info[1]):\n",
    "                        present_event = info[2]\n",
    "            print(present_event)\n",
    "\n",
    "    frame_slider = (0, (vol.shape[3]-1))\n",
    "    match dim:\n",
    "        case \"x\":\n",
    "            interact(plot, slice=(0, vol.shape[0]-1), frame=frame_slider)\n",
    "        case \"y\":\n",
    "            interact(plot, slice=(0, vol.shape[1]-1), frame=frame_slider)\n",
    "        case \"z\":\n",
    "            interact(plot, slice=(0, vol.shape[2]-1), frame=frame_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_image = ants.image_read(bold_stim_filepath)\n",
    "t1_image = ants.image_read(t1_input_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous Failures\n",
    "These are some things I've tried before, as an explanation as to why I'm writing out these large functions for stuff that should be just built into ANTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonical Way, register all frames within one function\n",
    "\n",
    "The following does not (it crashes the kernel):\n",
    "\n",
    "````python\n",
    "bold_registered = ants.apply_transforms(\n",
    "    fixed=t1_image,\n",
    "    moving=bold_image,\n",
    "    transformlist=registration['fwdtransforms'],\n",
    "    interpolator='linear',\n",
    "    imagetype=3\n",
    ")\n",
    "````\n",
    "\n",
    "I suspect this has to do with a glitch on the image type 3 as this was also an issue yesterday. Perhaps open an issue on github\n",
    "\n",
    "As a workaround, let's use a loop to cycle through all the 4th dimensional stuff.\n",
    "\n",
    "Given the computational lift of registration, let's write them to a list\n",
    "\n",
    "## Gathering the Transforms, then registering\n",
    "The following code proved problematic:\n",
    "````python\n",
    "registrations = []\n",
    "for frame in range(bold_image.shape[3]):\n",
    "    print(f\"frame {frame}/{bold_image.shape[3]}\")\n",
    "    print(\" creating bold frame\")\n",
    "    bold_frame = ants.from_numpy(bold_image.numpy()[:,:,:,frame])\n",
    "\n",
    "    print(\" Registering bold frame to T1 image\")\n",
    "    registration = ants.registration(\n",
    "    fixed=t1_image,\n",
    "    moving=bold_frame,\n",
    "    type_of_transform='Rigid'  # You can also use 'Affine' or 'SyN' for deformable registration\n",
    "    )\n",
    "    registrations += registration #This is incorrect! It's just adding the var names\n",
    "````\n",
    "When trying to apply these registrations, I got strange behavior. I believe this is because these `registration` values might be getting garbled behind the scenes somewhere. To get around this, let's see if one big function that gathers registrations and applies them does the trick!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, perhaps you could have made this a dictionary `img:transforms`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4D Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, here's our main alignment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_4D(bold_frames: list, data_template_idx=0, template_img_idx=0, time_starts = 0.0, time_spacing=2.0):\n",
    "    \"\"\"\n",
    "    Takes a list of BOLD frames and returns an ANTs image\n",
    "    \n",
    "    arguments:\n",
    "    ---------\n",
    "    template_img_idx : int\n",
    "        the frame from which you want to grab all the ANTs image data (spacing, etc)\n",
    "\n",
    "    time_starts : the starting origin for the temporal dimension\n",
    "\n",
    "    time_spacing : float\n",
    "        the temporal spacing, in terms of seconds per frame\n",
    "        Set as 2.0 for default to match the dataset I'm currently using\n",
    "    \"\"\"\n",
    "\n",
    "    if 0 > data_template_idx > len(bold_frames):\n",
    "        print(\"Data template index is not valid. Setting to first frame\")\n",
    "        data_template_idx = 0\n",
    "    t = bold_frames[template_img_idx] #t is for template\n",
    "    combined_origin = (t.origin[0], t.origin[1], t.origin[2], time_starts)\n",
    "    combined_spacing = (t.spacing[0], t.spacing[1], t.spacing[2], time_spacing)\n",
    "    # setting direction to just a 4D identity matrix. Not sure if this is correct but I think it is?\n",
    "\n",
    "    np_list = [frame.numpy()[:-1] for frame in bold_frames]\n",
    "    data = np.stack(np_list, axis=3)\n",
    "    combined_bold = ants.from_numpy(data, origin=combined_origin, spacing=combined_spacing, direction=np.eye(4))\n",
    "    return combined_bold\n",
    "\n",
    "\n",
    "\n",
    "def align_stabilized_bold_to_anat(stab_bold_img, t1_img):\n",
    "    \"\"\"\"\n",
    "    This function aligns an already stabilized BOLD image to a T1 anatomy image\n",
    "    by aligning the mean of the BOLD to the T1 anatomy\n",
    "    \"\"\"\n",
    "    print(\"Aligning stabilized bold to anat\\nEstablishing temporal mean\")\n",
    "\n",
    "\n",
    "    first_frame = ants.from_numpy(stab_bold_img.numpy()[:,:,:,0], spacing=stab_bold_img.spacing[:3])\n",
    "\n",
    "    frame_registration = ants.registration(\n",
    "        fixed=t1_image,\n",
    "        moving=first_frame,#temporal_mean,\n",
    "        type_of_transform=\"Rigid\", #haven't tried this one in earnest, tbh    \n",
    "    )\n",
    "    registered_frames = []\n",
    "    print(\"Applying transformations to frames\")\n",
    "    for frame in range(stab_bold_img.shape[3]):\n",
    "        print(f\"     frame{frame}/{stab_bold_img.shape[3]}\\n        creating bold frame\")\n",
    "        bold_frame = ants.from_numpy(stab_bold_img.numpy()[:,:,:,frame],\n",
    "                                     spacing=stab_bold_img.spacing[:3]) #again, assuming direction defaults to identity matrix\n",
    "        print(\"     Applying frame transformation\")\n",
    "        registered_frame = ants.apply_transforms(\n",
    "            fixed=t1_image,\n",
    "            moving=bold_frame,\n",
    "            transformlist=frame_registration['fwdtransforms'], #perhaps this could/should also be where the motin correction goes?\n",
    "            interpolator='linear'\n",
    "        )\n",
    "        #return bold_frame Returning the bold frame here does produce a non garbled result...\n",
    "        print(\"     adding registered frame to list\")\n",
    "        registered_frames.append(registered_frame)\n",
    "    print(\"Creating 4D numpy vol from list of 3D ANTs imgs\")\n",
    "    data = np.stack([frame.numpy() for frame in registered_frames], axis=3)\n",
    "    print(\"Creating 4D bold image from numpy vol\")\n",
    "    registered_bold_img = ants.from_numpy(data, origin=stab_bold_img.origin, spacing=stab_bold_img.spacing)\n",
    "    return registered_bold_img, data, registered_frames, first_frame #returning these to debug\n",
    "\n",
    "\n",
    "#It is in fact garbled at the registered_bold_img level\n",
    "#debug attempts:\n",
    "# [x] rigid transform\n",
    "#   The transform is now offset, and still garbled\n",
    "# [x] Test temporal mean\n",
    "#   It looks fine\n",
    "# [x] frame registration for first frame, not temporal mean\n",
    "#       This actually works!!!\n",
    "# [ ] frame registration for each frame\n",
    "\n",
    "#theres probably a way to dry align_stabilized_bold_to_anat and seq_to_4D. lots of similar logic. Should I DRY?\n",
    "#I'm thinking at the very least TODO an \"extrtact 3D\" frame function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test this, let's build a very short slice of the BOLD volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced = bold_image.numpy()[:, :, :, :3]\n",
    "bold_truncated_img = ants.from_numpy(sliced, spacing=bold_image.spacing, origin=bold_image.origin, direction=bold_image.direction)\n",
    "#hopefully the above args match all the metadata. I've printed to check but there might be some stuff hidden away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's motion correct it\n",
    "\n",
    "This returns a dictionary containing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stabilized = ants.motion_correction(bold_truncated_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And align it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning stabilized bold to anat\n",
      "Establishing temporal mean\n",
      " Creating frame registration\n",
      "Applying transformations to frames\n",
      "     frame0/3\n",
      "        creating bold frame\n",
      "     Applying frame transformation\n",
      "     adding registered frame to list\n",
      "     frame1/3\n",
      "        creating bold frame\n",
      "     Applying frame transformation\n",
      "     adding registered frame to list\n",
      "     frame2/3\n",
      "        creating bold frame\n",
      "     Applying frame transformation\n",
      "     adding registered frame to list\n",
      "Creating 4D numpy vol from list of 3D ANTs imgs\n",
      "Creating 4D bold image from numpy vol\n"
     ]
    }
   ],
   "source": [
    "aligned_bold_seq, numpy_data, frames_list, first_frame = align_stabilized_bold_to_anat(stabilized['motion_corrected'], t1_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454879ae54ea43189e8ca2b4f2430329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='slice', max=63), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explore_3D_vol(first_frame.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this is garbled on the numpy level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784a029df4034a38acf056d674c86f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=255, description='slice', max=511), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explore_3D_vol(frames_list[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b363939032b4899a29af156ed489491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=255, description='slice', max=511), IntSlider(value=1, description='fram…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explore_fMRI(aligned_bold_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_bold_alignment(aligned_bold_seq.numpy(), t1_image.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are certainly some motion correction jitters. I have some theories on why:\n",
    "\n",
    "- I couldn't add in the spacing and origin as the metadata while using `ants.from_numpy()` as it crashed the program\n",
    "\n",
    "- I need to explicitly run motion correction (the alignment somehow doesn't account for it)\n",
    "\n",
    "That being said, I feel like it's good enough for a proof of concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's run a (placehold) subtraction method on these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_BOLD_movement(bold_img):\n",
    "    \"\"\"\n",
    "    Each frame shows the difference between it and the previous frame. First frame is initialized at zero. \n",
    "    \"\"\"\n",
    "    origin =(bold_img.origin[0], bold_img.origin[1], bold_img.origin[2], bold_img.origin[3])\n",
    "    spacing = bold_img.spacing\n",
    "    direction = bold_img.direction\n",
    "    bold_np = np.empty_like(bold_img.numpy())\n",
    "\n",
    "    print(f\"origin {origin}\\nspacing {spacing}\\ndirection {direction}\")\n",
    "    print(bold_np.shape)\n",
    "    for frame in range(1, bold_np.shape[3]):\n",
    "        bold_np[:,:,:,frame] = np.absolute(bold_np[:,:,:,frame] - bold_np[:,:,:,frame - 1])\n",
    "    #output = ants.from_numpy(bold_np, origin=origin, spacing=spacing, direction=direction, has_components=True) #not sure about this bool\n",
    "    #return output\n",
    "    return bold_np #again with the crashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bold_movements_np = subtract_BOLD_movement(aligned_bold_seq) #This crashed the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bold_movements_img)\n",
    "\n",
    "#explore_fMRI(bold_movements_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_bold_alignment(t1_image.numpy(), bold_movements_img.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
