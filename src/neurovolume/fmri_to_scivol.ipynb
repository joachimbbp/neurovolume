{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering fMRI Data\n",
    "Both anatomical and functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_viewer_functions import *\n",
    "from functions import *\n",
    "from scivol import *\n",
    "import numpy as np\n",
    "import json\n",
    "import ants\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project root: /Users/joachimpfefferkorn/repos/neurovolume\n"
     ]
    }
   ],
   "source": [
    "proj_root = parent_directory()\n",
    "print(f\"project root: {proj_root}\")\n",
    "t1_input_filepath = os.path.join(proj_root, \"media/sub-01/anat/sub-01_T1w.nii.gz\")\n",
    "stimulus_filepath = os.path.join(proj_root, \"media/sub-01/func/sub-01_task-emotionalfaces_run-1_bold.nii.gz\")\n",
    "rest_filepath = os.path.join(proj_root, \"media/sub-01/func/sub-01_task-rest_bold.nii.gz\")\n",
    "mni_anat_filepath =  os.path.join(proj_root, \"templates/mni_icbm152_t1_tal_nlin_sym_09a.nii\")\n",
    "mni_mask_filepath = os.path.join(proj_root, \"templates/mni_icbm152_t1_tal_nlin_sym_09a_mask.nii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_t1_img = ants.image_read(t1_input_filepath)\n",
    "raw_stim_bold_img = ants.image_read(stimulus_filepath)\n",
    "raw_rest_bold_img = ants.image_read(rest_filepath)\n",
    "mni_img = ants.image_read(mni_anat_filepath)\n",
    "mni_mask_img = ants.image_read(mni_mask_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (64, 64, 35, 185)\n",
      "\t Spacing    : (4.0, 4.0, 4.0, 2.0)\n",
      "\t Origin     : (-127.953, 108.933, -74.8393, 0.0)\n",
      "\t Direction  : [ 1.  0.  0.  0.  0. -1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw_stim_bold_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize BOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO once integrated add masking\n",
    "default_cmap = 'nipy_spectral'\n",
    "default_figsize = (4,4)\n",
    "\n",
    "def explore_4D_vol(vol: np.ndarray, dim=\"x\"):\n",
    "    def x_coord(slice, time):\n",
    "        plt.figure(figsize=default_figsize)\n",
    "        plt.imshow(vol[slice,:,:,time], cmap=default_cmap)\n",
    "    def y_coord(slice, time):\n",
    "        plt.figure(figsize=default_figsize)\n",
    "        plt.imshow(vol[:,slice,:,time], cmap=default_cmap)    \n",
    "    def z_coord(slice, time):\n",
    "        plt.figure(figsize=default_figsize)\n",
    "        plt.imshow(vol[:,:,slice,time], cmap=default_cmap)\n",
    "    match dim:\n",
    "        case \"x\":\n",
    "            interact(x_coord, slice=(0, vol.shape[0]-1), time=(0, (vol.shape[3]-1)))\n",
    "        case \"y\":\n",
    "            interact(y_coord, slice=(0, vol.shape[1]-1), time=(0, (vol.shape[3]-1)))\n",
    "        case \"z\":\n",
    "            interact(z_coord, slice=(0, vol.shape[2]-1), time=(0, (vol.shape[3]-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "print(raw_stim_bold_img.numpy().shape[3]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dce678520804b95999fd346ba76050d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='slice', max=63), IntSlider(value=92, description='time'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f52a41448d04affa599657ed9fd5683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='slice', max=63), IntSlider(value=92, description='time'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fb095a1d2545b5acc457bd6c6ba4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=17, description='slice', max=34), IntSlider(value=92, description='time'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explore_4D_vol(raw_stim_bold_img.numpy(), dim=\"x\")\n",
    "explore_4D_vol(raw_stim_bold_img.numpy(), dim=\"y\")\n",
    "explore_4D_vol(raw_stim_bold_img.numpy(), dim=\"z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is it really only 184 time slices? whats the frame rate here?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtract Baseline from Stimulus to Isolate the Activations\n",
    "\n",
    "So it looks like this experiment doesn't have a neutral stimulus, just a \"rest\" . This isn't great, I'd much prefer a Block Design. There are a couple of ways we could build an experiment. One thought I had would be to take the mean of the rest state and then read the activations as being against that? *Is this valid?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_average_rest = np.mean(raw_rest_bold_img.numpy(), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d6525f348143878b71f7aebf326b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='slice', max=63), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 35)\n"
     ]
    }
   ],
   "source": [
    "explore_3D_vol(temporal_average_rest)\n",
    "print(temporal_average_rest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_neutral_3D(experimental, neutral):\n",
    "    \"\"\"\n",
    "    Subtracts a 3D neutral from each time slice in a 4D experimental volume\n",
    "    For use in experiments which lack a block design and for which the \n",
    "    neutral stimulus has been derived from an averaged rest state\n",
    "    \"\"\"\n",
    "    result = np.empty_like(experimental)\n",
    "    for time_slice in range(experimental.shape[3]):\n",
    "        result[:,:,:,time_slice] = experimental[:,:,:, time_slice] - neutral\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated_BOLD = subtract_neutral_3D(raw_stim_bold_img.numpy(), temporal_average_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9803aeb5c24f018aecc0da621feb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='slice', max=63), IntSlider(value=92, description='time'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explore_4D_vol(isolated_BOLD, dim=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Change in Volume\n",
    "Here's another possible approach. Again, I do not know the scientific validity of this. Here we'll take each frame and measure the difference in the bold response from the previous frame.\n",
    "\n",
    "Grabbing the absolute value between the current and previous timestamp creates the most convenient isolation for our visualization tool. However, this does not mean that it is the most scientifically valuable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_BOLD_movement(bold_vol, baseline_vol):\n",
    "    \"\"\"\n",
    "    Each frame shows the difference between it and the previous frame. First frame is initialized at zero. \n",
    "    \"\"\"\n",
    "    result = np.empty_like(bold_vol)\n",
    "    for time_slice in range(1, bold_vol.shape[3]):\n",
    "        result[:,:,:,time_slice] = np.absolute(bold_vol[:,:,:,time_slice] - bold_vol[:,:,:,time_slice - 1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_movement = measure_BOLD_movement(raw_stim_bold_img.numpy(), temporal_average_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958f58f527654d108287bf93313fc1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='slice', max=63), IntSlider(value=92, description='time'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explore_4D_vol(bold_movement)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
