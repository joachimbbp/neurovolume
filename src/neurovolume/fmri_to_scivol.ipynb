{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering fMRI Data\n",
    "Both anatomical and functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_viewer_functions import *\n",
    "from functions import *\n",
    "from scivol import *\n",
    "import numpy as np\n",
    "import json\n",
    "import ants\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project root: /Users/joachimpfefferkorn/repos/neurovolume\n"
     ]
    }
   ],
   "source": [
    "proj_root = parent_directory()\n",
    "print(f\"project root: {proj_root}\")\n",
    "t1_input_filepath = os.path.join(proj_root, \"media/sub-01/anat/sub-01_T1w.nii.gz\")\n",
    "stimulus_filepath = os.path.join(proj_root, \"media/sub-01/func/sub-01_task-emotionalfaces_run-1_bold.nii.gz\")\n",
    "rest_filepath = os.path.join(proj_root, \"media/sub-01/func/sub-01_task-rest_bold.nii.gz\")\n",
    "mni_anat_filepath =  os.path.join(proj_root, \"templates/mni_icbm152_t1_tal_nlin_sym_09a.nii\")\n",
    "mni_mask_filepath = os.path.join(proj_root, \"templates/mni_icbm152_t1_tal_nlin_sym_09a_mask.nii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_t1_img = ants.image_read(t1_input_filepath)\n",
    "raw_stim_bold_img = ants.image_read(stimulus_filepath)\n",
    "raw_rest_bold_img = ants.image_read(rest_filepath)\n",
    "mni_img = ants.image_read(mni_anat_filepath)\n",
    "mni_mask_img = ants.image_read(mni_mask_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTsImage\n",
      "\t Pixel Type : float (float32)\n",
      "\t Components : 1\n",
      "\t Dimensions : (64, 64, 35, 185)\n",
      "\t Spacing    : (4.0, 4.0, 4.0, 2.0)\n",
      "\t Origin     : (-127.953, 108.933, -74.8393, 0.0)\n",
      "\t Direction  : [ 1.  0.  0.  0.  0. -1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw_stim_bold_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize BOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO once integrated add masking\n",
    "default_cmap = 'nipy_spectral'\n",
    "default_figsize = (4,4)\n",
    "\n",
    "def explore_4D_vol(vol: np.ndarray, dim=\"x\"):\n",
    "    def x_coord(slice, time):\n",
    "        plt.figure(figsize=default_figsize)\n",
    "        plt.imshow(vol[slice,:,:,time], cmap=default_cmap)\n",
    "    def y_coord(slice, time):\n",
    "        plt.figure(figsize=default_figsize)\n",
    "        plt.imshow(vol[:,slice,:,time], cmap=default_cmap)    \n",
    "    def z_coord(slice, time):\n",
    "        plt.figure(figsize=default_figsize)\n",
    "        plt.imshow(vol[:,:,slice,time], cmap=default_cmap)\n",
    "    match dim:\n",
    "        case \"x\":\n",
    "            interact(x_coord, slice=(0, vol.shape[0]-1), time=(0, (vol.shape[3]-1)))\n",
    "        case \"y\":\n",
    "            interact(y_coord, slice=(0, vol.shape[1]-1), time=(0, (vol.shape[3]-1)))\n",
    "        case \"z\":\n",
    "            interact(z_coord, slice=(0, vol.shape[2]-1), time=(0, (vol.shape[3]-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "print(raw_stim_bold_img.numpy().shape[3]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8261a2e51b4d4095e7a34b71ee39c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='slice', max=63), IntSlider(value=92, description='time'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c991d71d31f48f58a982c91e8a698c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='slice', max=63), IntSlider(value=92, description='time'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df346c6b8da74fe3ab669ca62ce0492e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=17, description='slice', max=34), IntSlider(value=92, description='time'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explore_4D_vol(raw_stim_bold_img.numpy(), dim=\"x\")\n",
    "explore_4D_vol(raw_stim_bold_img.numpy(), dim=\"y\")\n",
    "explore_4D_vol(raw_stim_bold_img.numpy(), dim=\"z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is it really only 184 time slices? whats the frame rate here?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtract Baseline from Stimulus to Isolate the Activations\n",
    "\n",
    "So it looks like this experiment doesn't have a neutral stimulus, just a \"rest\" . This isn't great, I'd much prefer a Block Design. There are a couple of ways we could build an experiment. One thought I had would be to take the mean of the rest state and then read the activations as being against that? *Is this valid?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_average_rest = np.mean(raw_rest_bold_img.numpy(), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b5f4f50e2748948d75b7a07ab56672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='slice', max=63), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 35)\n"
     ]
    }
   ],
   "source": [
    "explore_3D_vol(temporal_average_rest)\n",
    "print(temporal_average_rest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_neutral_3D(experimental, neutral):\n",
    "    \"\"\"\n",
    "    Subtracts a 3D neutral from each time slice in a 4D experimental volume\n",
    "    For use in experiments which lack a block design and for which the \n",
    "    neutral stimulus has been derived from an averaged rest state\n",
    "    \"\"\"\n",
    "    result = np.empty_like(experimental)\n",
    "    for time_slice in range(experimental.shape[3]):\n",
    "        result[:,:,:,time_slice] = experimental[:,:,:, time_slice] - neutral\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated_BOLD = subtract_neutral_3D(raw_stim_bold_img.numpy(), temporal_average_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18125f9d2e394c1abaf0db46a900d6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='slice', max=63), IntSlider(value=92, description='time'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explore_4D_vol(isolated_BOLD, dim=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Change in Volume\n",
    "Here's another possible approach. Again, I do not know the scientific validity of this. Here we'll take each frame and measure the difference in the bold response from the previous frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_BOLD_movement(bold_vol):\n",
    "    \"\"\"\n",
    "    Each frame shows the difference between it and the previous frame. First frame is initialized at zero. \n",
    "    \"\"\"\n",
    "    result = np.empty_like(bold_vol)\n",
    "    for time_slice in range(1, bold_vol.shape[3]):\n",
    "        result[:,:,:time_slice] = result[:,:,:time_slice] - result[:,:,:time_slice - 1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1, 5)\n"
     ]
    }
   ],
   "source": [
    "bold_movement = measure_BOLD_movement() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
